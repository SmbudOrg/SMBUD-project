{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/07 02:16:54 WARN Utils: Your hostname, MacBook-Pro-di-Cristina.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)\n",
      "22/12/07 02:16:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/07 02:16:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/12/07 02:16:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/12/07 02:16:56 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/12/07 02:16:56 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/12/07 02:16:56 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/12/07 02:16:56 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "22/12/07 02:16:56 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "22/12/07 02:16:56 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n",
      "22/12/07 02:16:56 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n",
      "22/12/07 02:16:56 WARN Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.\n"
     ]
    }
   ],
   "source": [
    "# Import the basic spark library\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create an entry point to the PySpark Application\n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local\") \\\n",
    "      .appName(\"schemaBook\") \\\n",
    "      .getOrCreate()\n",
    "# master contains the URL of your remote spark instance or 'local'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- orcid: string (nullable = true)\n",
      " |-- citations: long (nullable = true)\n",
      " |-- crossref: string (nullable = true)\n",
      " |-- editor: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- orcid: string (nullable = true)\n",
      " |-- ee: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- isbn: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- keyword: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- pages: long (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- series: struct (nullable = true)\n",
      " |    |-- href: string (nullable = true)\n",
      " |    |-- title: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- volume: long (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#schema book\n",
    "df_book = spark.read.option(\"multiline\",\"true\").json(\"book-db-manual.json\")\n",
    "df_book.printSchema()\n",
    "#df_book.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- orcid: string (nullable = true)\n",
      " |-- citations: long (nullable = true)\n",
      " |-- cite: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ee: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- journal: string (nullable = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- keyword: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- note: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- pages: long (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- volume: long (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#schema article\n",
    "df_article = spark.read.option(\"multiline\",\"true\").json(\"article-db-manual_conrefs.json\")\n",
    "df_article.printSchema()\n",
    "#df_article.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- orcid: string (nullable = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- note: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- url: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#schema www\n",
    "df_www = spark.read.option(\"multiline\",\"true\").json(\"www-db-manual.json\")\n",
    "df_www.printSchema()\n",
    "#df_www.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "0.1.4 VERSION 2: Best PROFESSORS according to number of citations at a given university\n",
    "\n",
    "The following query can be used to find the authors affiliated with a specific university\n",
    "(e.g.’Stanford University, USA’) ordering them by the average number of citations(at least 5) received by their articles from any other publication in the last years(from 2000)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#import\n",
    "from pyspark.sql.functions import col                       # Filtering using the col() function\n",
    "from pyspark.sql.functions import array_contains            # Filtering on array columns\n",
    "from pyspark.sql.functions import explode                   # Explode Arrays in Individual Rows\n",
    "from pyspark.sql.functions import collect_list\n",
    "from pyspark.sql.functions import avg, count                # Multiple Aggregations\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "selected_df_book = df_book  \\\n",
    "    .select(df_book.key, df_book.year)\n",
    "#exploded_df_book.printSchema()\n",
    "#exploded_df_book.show(truncate=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "selected_df_article = df_article  \\\n",
    "    .select(df_article.key, df_article.author, df_article.cite, df_article.year )\n",
    "#selected_df_article.printSchema()\n",
    "#selected_df_article.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- orcid: string (nullable = true)\n",
      "\n",
      "+--------------------------------------------------+\n",
      "|author                                            |\n",
      "+--------------------------------------------------+\n",
      "|{Jennifer Widom, Jennifer Widom}                  |\n",
      "|{Gio Wiederhold, Gio Wiederhold}                  |\n",
      "|{Janet L. Wiener, Janet L. Wiener}                |\n",
      "|{Terry Winograd, Terry Winograd}                  |\n",
      "|{William J. Dally, William J. Dally}              |\n",
      "|{William (Bill) J. Dally, William (Bill) J. Dally}|\n",
      "|{Bill Dally, Bill Dally}                          |\n",
      "|{Jeffrey D. Ullman, Jeffrey D. Ullman}            |\n",
      "|{Yue Zhuge, Yue Zhuge}                            |\n",
      "|{Prabhakar Raghavan, Prabhakar Raghavan}          |\n",
      "|{Alexander Aiken, Alexander Aiken}                |\n",
      "|{Alex Aiken, Alex Aiken}                          |\n",
      "|{Sergey Brin, Sergey Brin}                        |\n",
      "|{Wilburt Labio, Wilburt Labio}                    |\n",
      "|{Andreas Paepcke, Andreas Paepcke}                |\n",
      "|{Avi Pfeffer, Avi Pfeffer}                        |\n",
      "|{Tak W. Yan, Tak W. Yan}                          |\n",
      "|{Hector Garcia-Molina, Hector Garcia-Molina}      |\n",
      "|{Himanshu Gupta, Himanshu Gupta}                  |\n",
      "|{Carolyn L. Talcott, Carolyn L. Talcott}          |\n",
      "+--------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df_www=df_www.filter(array_contains(df_www.note, \"Stanford University, USA\")).select(explode(df_www.author)).withColumnRenamed(\"col\", \"author\")\n",
    "filtered_df_www.printSchema()\n",
    "filtered_df_www.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df_pub= selected_df_article.unionByName(selected_df_book, allowMissingColumns=True).filter(col(\"year\")>2000).withColumnRenamed(\"key\", \"key_p\")\n",
    "#df_pub.printSchema()\n",
    "#df_pub.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "exploded_df_article=selected_df_article.select(selected_df_article.key, selected_df_article.author, explode(selected_df_article.cite)).withColumnRenamed(\"col\", \"cite\")\n",
    "#exploded_df_article.printSchema()\n",
    "#exploded_df_article.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "exploded_df_article=exploded_df_article.join(df_pub,exploded_df_article.cite==df_pub.key_p, \"left\").select(exploded_df_article.key, explode(exploded_df_article.author), exploded_df_article.cite,df_pub.key_p).filter(df_pub.key_p.isNotNull()).drop(df_pub.key_p).withColumnRenamed(\"col\", \"author\").groupBy(\"key\").agg(count(\"cite\").alias(\"CountOfCitations\"),collect_list(\"author\").alias(\"author\")).select(col(\"key\"), col(\"CountOfCitations\"), explode(col(\"author\"))).withColumnRenamed(\"col\", \"author\")\n",
    "#exploded_df_article.printSchema()\n",
    "#exploded_df_article.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- Avg Cit: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|name                |Avg Cit           |\n",
      "+--------------------+------------------+\n",
      "|Yue Zhuge           |40.0              |\n",
      "|Wilburt Labio       |40.0              |\n",
      "|Prabhakar Raghavan  |30.352941176470587|\n",
      "|Janet L. Wiener     |24.0              |\n",
      "|Andreas Paepcke     |21.0              |\n",
      "|Jeffrey D. Ullman   |19.23076923076923 |\n",
      "|Jennifer Widom      |18.01818181818182 |\n",
      "|Hector Garcia-Molina|16.11111111111111 |\n",
      "|Avi Pfeffer         |16.0              |\n",
      "|William J. Dally    |14.0              |\n",
      "|Gio Wiederhold      |13.393939393939394|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = filtered_df_www.join(exploded_df_article, filtered_df_www.author == exploded_df_article.author, \"left\").drop(exploded_df_article.author).groupBy(\"author\").agg(avg(\"CountOfCitations\").alias(\"Avg Cit\")).filter(col(\"Avg Cit\")>=\"5\").select(col(\"author.name\"), col(\"Avg Cit\")).sort(col(\"Avg Cit\").desc())\n",
    "\n",
    "result.printSchema()\n",
    "result.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
