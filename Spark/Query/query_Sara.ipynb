{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, ArrayType\n",
    "from pyspark.sql.functions import col                       # Filtering using the col() function\n",
    "from pyspark.sql.functions import array_contains            # Filtering on array columns\n",
    "from pyspark.sql.functions import explode                   # Explode Arrays in Individual Rows\n",
    "from pyspark.sql.functions import sum, avg, count, max      # Multiple Aggregations\n",
    "from pyspark.sql.functions import first, last\n",
    "\n",
    "# Create an entry point to the PySpark Application\n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local\") \\\n",
    "      .appName(\"MyFirstSparkApplication\") \\\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT\n",
    "\n",
    "df_book = spark.read.option(\"multiline\",\"true\")  \\\n",
    "      .json(\"Datasets (json)/book-db.json\")\n",
    "\n",
    "df_article = spark.read.option(\"multiline\",\"true\")  \\\n",
    "      .json(\"Datasets (json)/article-db.json\")\n",
    "\n",
    "df_incollection = spark.read.option(\"multiline\",\"true\")  \\\n",
    "      .json(\"Datasets (json)/incollection-db.json\")\n",
    "\n",
    "df_www = spark.read.option(\"multiline\",\"true\")  \\\n",
    "      .json(\"Datasets (json)/www-db.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Find SERIES about relational databases </h3>\n",
    "Series that contain books about relational databases published after 2018, ordered by the year of the most recent publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------------+---------------+\n",
      "|        Series title|          Series key|Number of books|Most recent pub|\n",
      "+--------------------+--------------------+---------------+---------------+\n",
      "|Studies in Comput...|db/series/sci/ind...|              5|           2022|\n",
      "|Springer Briefs i...|db/series/sbcs/in...|              3|           2022|\n",
      "|Synthesis Lecture...|db/series/synthes...|              1|           2021|\n",
      "|History of Computing|db/series/hoc/ind...|              1|           2021|\n",
      "|Synthesis Lecture...|db/series/synthes...|              1|           2021|\n",
      "|Lecture Notes in ...|db/series/lncs/in...|              2|           2020|\n",
      "|Intelligent Syste...|db/series/isrl/in...|              2|           2020|\n",
      "|Texts in Computer...|db/series/txcs/in...|              1|           2020|\n",
      "|Monographs in The...|db/series/eatcs/i...|              1|           2020|\n",
      "+--------------------+--------------------+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = df_book.\\\n",
    "    filter((col(\"series\").isNotNull()) & (array_contains(col(\"keyword\"), \"relational databases\"))). \\\n",
    "    groupBy(\"series\").\\\n",
    "    agg(count(\"key\").alias(\"count\"), max(\"year\").alias(\"Most recent pub\")).\\\n",
    "    filter(col(\"Most recent pub\")>2018).\\\n",
    "    sort(col(\"Most recent pub\").desc(), col(\"count\").desc()).\\\n",
    "    select(col(\"series.title\").alias(\"Series title\"), col(\"series.href\").alias(\"Series key\"),\n",
    "        col(\"count\").alias(\"Number of books\"), col(\"Most recent pub\"))\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2. Top KEYWORDS used with another keyword </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----+\n",
      "|keyword                     |count|\n",
      "+----------------------------+-----+\n",
      "|minimum path                |20   |\n",
      "|database design             |20   |\n",
      "|dijkstra                    |20   |\n",
      "|software                    |20   |\n",
      "|c++                         |19   |\n",
      "|interfaces                  |17   |\n",
      "|computer science engineering|17   |\n",
      "|q-learning                  |17   |\n",
      "|A*                          |17   |\n",
      "|key-value databases         |16   |\n",
      "|java                        |16   |\n",
      "|neo4j                       |15   |\n",
      "|machine learning            |15   |\n",
      "|c89                         |15   |\n",
      "|graph model                 |15   |\n",
      "|big data                    |14   |\n",
      "|javascript                  |14   |\n",
      "|graphs                      |14   |\n",
      "|ai                          |13   |\n",
      "|markov decision process     |13   |\n",
      "+----------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pub_book = df_book.select(col(\"key\"), col(\"keyword\"))\n",
    "pub_article = df_article.select(col(\"key\"), col(\"keyword\"))\n",
    "\n",
    "df_publications = pub_book.union(pub_article)\n",
    "\n",
    "result = df_publications.\\\n",
    "    filter(array_contains(col(\"keyword\"), \"data mining\")).\\\n",
    "    select(col(\"key\"), explode(\"keyword\")).\\\n",
    "    withColumnRenamed(\"col\", \"keyword\").\\\n",
    "    filter(col(\"keyword\") != \"data mining\").\\\n",
    "    groupBy(\"keyword\").count().\\\n",
    "    sort(col(\"count\").desc())\n",
    "\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3. Top BOOKS about a specific topic </h3>\n",
    "Find books containing more than 2 incollections about deep learning or machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-------------+-----+\n",
      "|               title|year|citations sum|count|\n",
      "+--------------------+----+-------------+-----+\n",
      "|Software Sustaina...|2021|          142|    2|\n",
      "|Towards Interoper...|2020|          136|    2|\n",
      "|Integrating Resea...|2020|           57|    2|\n",
      "|Encyclopedia of E...|2020|         null|    2|\n",
      "|Encyclopedia of D...|2018|          700|   15|\n",
      "|Applications of B...|2018|           32|    2|\n",
      "|Developing Suppor...|2018|         null|    2|\n",
      "|Software for Exas...|2016|         null|    2|\n",
      "+--------------------+----+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "incollection_kw = df_incollection.filter(array_contains(col(\"keyword\"), \"deep learning\")\n",
    "        | array_contains(col(\"keyword\"), \"machine learning\")).\\\n",
    "    select(col(\"key\"), col(\"crossref\"), col(\"citations\"))\n",
    "\n",
    "result = df_book.join(incollection_kw, df_book.key == incollection_kw.crossref).\\\n",
    "    select(df_book.key, df_book.title, df_book.year, incollection_kw.key, incollection_kw.citations).\\\n",
    "    groupBy(df_book.key, df_book.title, df_book.year).\\\n",
    "    agg(sum(incollection_kw.citations).alias(\"citations sum\"),\n",
    "        count(incollection_kw.key).alias(\"count\")).\\\n",
    "    filter(col(\"count\") >= 2).\\\n",
    "    sort(col(\"year\").desc(), col(\"citations sum\").desc()).\\\n",
    "    select(col(\"title\"), col(\"year\"), col(\"citations sum\"), col(\"count\"))\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----+\n",
      "|col                         |count|\n",
      "+----------------------------+-----+\n",
      "|cloud computing             |132  |\n",
      "|debugging                   |127  |\n",
      "|deep learning               |127  |\n",
      "|graph model                 |126  |\n",
      "|javascript                  |126  |\n",
      "|key-value databases         |125  |\n",
      "|html                        |124  |\n",
      "|ai                          |124  |\n",
      "|software engineering        |123  |\n",
      "|interfaces                  |123  |\n",
      "|data processing             |123  |\n",
      "|path finding                |122  |\n",
      "|python                      |121  |\n",
      "|software                    |120  |\n",
      "|A*                          |120  |\n",
      "|unstructured data           |119  |\n",
      "|computer science engineering|119  |\n",
      "|c#                          |119  |\n",
      "|mongodb                     |118  |\n",
      "|graph search                |116  |\n",
      "+----------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Most used keywords\n",
    "exploded_kw = df_incollection.filter(col(\"keyword\").isNotNull())  \\\n",
    "    .select(col(\"key\"), explode(\"keyword\"))\n",
    "exploded_kw.groupBy(\"col\").count().sort(col(\"count\").desc()).show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82f21b5b30e598e0a4ca5a68516cbe3ef1f3939a9a660daae059d64a2920506a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
