{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, ArrayType\n",
    "from pyspark.sql.functions import col                       # Filtering using the col() function\n",
    "from pyspark.sql.functions import array_contains            # Filtering on array columns\n",
    "from pyspark.sql.functions import explode                   # Explode Arrays in Individual Rows\n",
    "from pyspark.sql.functions import sum, avg, count, max      # Multiple Aggregations\n",
    "from pyspark.sql.functions import first, last\n",
    "\n",
    "# Create an entry point to the PySpark Application\n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local\") \\\n",
    "      .appName(\"MyFirstSparkApplication\") \\\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT\n",
    "\n",
    "df_book = spark.read.option(\"multiline\",\"true\")  \\\n",
    "      .json(\"Datasets (json)/book-db.json\")\n",
    "\n",
    "df_article = spark.read.option(\"multiline\",\"true\")  \\\n",
    "      .json(\"Datasets (json)/article-db.json\")\n",
    "\n",
    "df_incollection = spark.read.option(\"multiline\",\"true\")  \\\n",
    "      .json(\"Datasets (json)/incollection-db.json\")\n",
    "\n",
    "df_www = spark.read.option(\"multiline\",\"true\")  \\\n",
    "      .json(\"Datasets (json)/www-db.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Find SERIES about relational databases </h3>\n",
    "Series that contain at least 2 books about relational databases, ordered by the year of the most recent publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------------+---------------+\n",
      "|        Series title|          Series key|Number of books|Most recent pub|\n",
      "+--------------------+--------------------+---------------+---------------+\n",
      "|Studies in Comput...|db/series/sci/ind...|              5|           2022|\n",
      "|Springer Briefs i...|db/series/sbcs/in...|              3|           2022|\n",
      "|Intelligent Syste...|db/series/isrl/in...|              2|           2020|\n",
      "|Lecture Notes in ...|db/series/lncs/in...|              2|           2020|\n",
      "|Studies in Fuzzin...|db/series/sfsc/in...|              2|           2015|\n",
      "+--------------------+--------------------+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = df_book.\\\n",
    "    filter((col(\"series\").isNotNull()) & (array_contains(col(\"keyword\"), \"relational databases\"))). \\\n",
    "    groupBy(\"series\").\\\n",
    "    agg(count(\"key\").alias(\"count\"), max(\"year\").alias(\"Most recent pub\")).\\\n",
    "    filter(col(\"count\")>=2).\\\n",
    "    sort(col(\"Most recent pub\").desc(), col(\"count\").desc()).\\\n",
    "    select(col(\"series.title\").alias(\"Series title\"), col(\"series.href\").alias(\"Series key\"),\n",
    "        col(\"count\").alias(\"Number of books\"), col(\"Most recent pub\"))\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----+\n",
      "|col                    |count|\n",
      "+-----------------------+-----+\n",
      "|q-learning             |62   |\n",
      "|relational databases   |61   |\n",
      "|graph database         |52   |\n",
      "|language processing    |51   |\n",
      "|A*                     |50   |\n",
      "|mongodb                |50   |\n",
      "|computer science       |49   |\n",
      "|minimum path           |48   |\n",
      "|database design        |48   |\n",
      "|software               |48   |\n",
      "|data mining            |47   |\n",
      "|computer architectures |46   |\n",
      "|machine learning       |45   |\n",
      "|markov decision process|45   |\n",
      "|multiagent systems     |45   |\n",
      "|c#                     |44   |\n",
      "|neo4j                  |44   |\n",
      "|graphs                 |43   |\n",
      "|data processing        |43   |\n",
      "|c89                    |42   |\n",
      "+-----------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Most used keywords in books\n",
    "exploded_kw = df_book.filter(col(\"keyword\").isNotNull())  \\\n",
    "    .select(df_book.key, explode(\"keyword\"))\n",
    "exploded_kw.groupBy(\"col\").count().sort(col(\"count\").desc()).show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82f21b5b30e598e0a4ca5a68516cbe3ef1f3939a9a660daae059d64a2920506a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
