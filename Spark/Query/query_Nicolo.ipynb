{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, ArrayType\n",
    "from pyspark.sql.functions import col                       # Filtering using the col() function\n",
    "from pyspark.sql.functions import array_contains            # Filtering on array columns\n",
    "from pyspark.sql.functions import explode                   # Explode Arrays in Individual Rows\n",
    "from pyspark.sql.functions import sum, avg, count, max      # Multiple Aggregations\n",
    "from pyspark.sql.functions import first, last\n",
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark.sql.functions import lit, array\n",
    "\n",
    "# Create an entry point to the PySpark Application\n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local\") \\\n",
    "      .appName(\"MyFirstSparkApplication\") \\\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT\n",
    "\n",
    "df_book = spark.read.option(\"multiline\",\"true\")  \\\n",
    "      .json(\"Datasets/book-db.json\")\n",
    "\n",
    "df_article = spark.read.option(\"multiline\",\"true\")  \\\n",
    "      .json(\"Datasets/article-db.json\")\n",
    "\n",
    "df_incollection = spark.read.option(\"multiline\",\"true\")  \\\n",
    "      .json(\"Datasets/incollection-db.json\")\n",
    "\n",
    "df_www = spark.read.option(\"multiline\",\"true\")  \\\n",
    "      .json(\"Datasets/www-db.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article.show()\n",
    "df_book.show()\n",
    "df_incollection.show()\n",
    "df_www.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Top Journals for heterogeneity of topics**\n",
    "This query is useful to obtain the journals which are the most heterogeneous, i.e. the ones whose articles cover a good number of topics. \n",
    "In this case, we want the top 10 journals that have published articles related to at least 25 different keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+------------------+\n",
      "|journal                     |number of keywords|\n",
      "+----------------------------+------------------+\n",
      "|SIGMOD Rec.                 |45                |\n",
      "|IEEE Trans. Knowl. Data Eng.|45                |\n",
      "|IEEE Data Eng. Bull.        |45                |\n",
      "|ACM SIGMOD Digit. Rev.      |45                |\n",
      "|IWBS Report                 |45                |\n",
      "|ACM Trans. Database Syst.   |45                |\n",
      "|VLDB J.                     |45                |\n",
      "|LILOG-Report                |44                |\n",
      "|ACM Comput. Surv.           |44                |\n",
      "|Commun. ACM                 |28                |\n",
      "+----------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = df_article \\\n",
    "    .select(col(\"journal\"), explode(\"keyword\")) \\\n",
    "    .withColumnRenamed(\"col\", \"keyword\") \\\n",
    "    .groupBy(\"journal\") \\\n",
    "    .agg(countDistinct(\"journal\", \"keyword\")) \\\n",
    "    .withColumnRenamed(\"count(journal, keyword)\", \"number of keywords\") \\\n",
    "    .filter(col(\"number of keywords\") > 25) \\\n",
    "    .sort(col(\"number of keywords\").desc())\n",
    "    \n",
    "result.limit(10).show(truncate = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Find books not treating a certain topic and related to favourite Publishers**\n",
    "This query is useful if you want to buy a book that has been published by one of your favourite publishers but does not treat a certain topic, for example because you have already studied it or because you just simply don't like it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+----------------+-------------------------------------------+----+\n",
      "|isbn                                  |publisher       |title                                      |year|\n",
      "+--------------------------------------+----------------+-------------------------------------------+----+\n",
      "|[978-94-6239-185-7, 978-94-6239-186-4]|Atlantis Press  |Introduction to Text Visualization         |2016|\n",
      "|[9781138207950]                       |Routledge       |Cognitive Design for Artificial Minds      |2021|\n",
      "|[978-1-611-97368-6]                   |SIAM            |Evaluating Gas Network Capacities          |2015|\n",
      "|[978-981-4632-12-6, 978-981-4632-14-0]|World Scientific|Adaptive Cloud Enterprise Architecture     |2015|\n",
      "|[9781315369228]                       |CRC Press       |Information Theory Tools for Visualization.|2016|\n",
      "+--------------------------------------+----------------+-------------------------------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "favourite_publishers = [\"CRC Press\", \"World Scientific\", \"Routledge\", \"SIAM\", \"Atlantis Press\"]\n",
    "hated_topic = \"data processing\"\n",
    "df_book_favPubl = df_book.filter(col(\"publisher\").isin(favourite_publishers))\n",
    "result = df_book_favPubl.filter(array_contains(df_book_favPubl.keyword, hated_topic) == False) \\\n",
    "    .select(col(\"isbn\"), col(\"publisher\"), col(\"title\"), col(\"year\")) \\\n",
    "    .limit(5) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Update the available URL for a certain author**\n",
    "This query could be useful in a scenario where an author decides that the link to his webpage (specified by him to the dataframe admin) should be the only link available among the various URLs associated to him in the dataframe, thus deleting all the other URLs uploaded in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------------------------------+\n",
      "|name         |url                                           |\n",
      "+-------------+----------------------------------------------+\n",
      "|Elena Ferrari|http://www.dicom.uninsubria.it/~elena.ferrari/|\n",
      "+-------------+----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_www_exploded = df_www  \\\n",
    "    .select(explode(df_www.author), df_www.url)   \\\n",
    "    .withColumnRenamed(\"col\", \"author\")\n",
    "\n",
    "result = df_www_exploded \\\n",
    "    .filter(col(\"author.name\") == \"Elena Ferrari\") \\\n",
    "    .withColumn(\"url\", lit(\"http://www.dicom.uninsubria.it/~elena.ferrari/\")) \\\n",
    "    .select(col(\"author.name\"), col(\"url\")) \\\n",
    "    .show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19d762ffc7d2f958e0963c75da0d959adf181f4ac62524ed3e80179df28269f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
